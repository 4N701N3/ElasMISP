# Flask Configuration
FLASK_ENV=development
FLASK_APP=app
SECRET_KEY=your-super-secret-key-change-in-production

# Site Configuration
SITE_NAME=ElasMISP
SITE_TITLE=ElasMISP

# Elasticsearch Configuration
ELASTICSEARCH_URL=http://localhost:9200
ELASTICSEARCH_USER=elastic
ELASTICSEARCH_PASSWORD=elastic123
ELASTICSEARCH_MEMORY_XMS=256m
ELASTICSEARCH_MEMORY_XMX=256m

# Redis
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1

# Default Admin User (created on first startup)
DEFAULT_ADMIN_USER=admin
DEFAULT_ADMIN_PASSWORD=admin123
# Demo Data Generation (set to 'true' to populate with random IOCs on first run)
DEMO_DATA_ENABLED=false

# LLM Report Generation Configuration
# Add these to your .env file to enable LLM-based report generation

# Enable LLM report generation
LLM_ENABLED=false

# LLM Provider URL
# For Docker Ollama: http://ollama:11434 (service name in docker-compose)
# For local Ollama: http://localhost:11434
# For OpenAI: https://api.openai.com/v1
LLM_URL=http://ollama:11434

# LLM Model to use
# Ollama models: mistral, llama2, neural-chat, orca-mini, etc.
# OpenAI models: gpt-3.5-turbo, gpt-4, etc.
LLM_MODEL=mistral
# LLM API Key (required for OpenAI)
LLM_API_KEY=